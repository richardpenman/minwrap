# -*- coding: utf-8 -*-

__doc__ = 'Allow classifying inputs and extending them to all cases in the same domain'

import collections, csv, glob, threading
import common, parser


def hash_key(value):
    """Define a hash for this value that ignores case
    """
    return hash(str(value).lower())


vertical_data = collections.defaultdict(dict)
def load_data():
    """Load sample vertical data into a dictionary with a key for each column
    """
    common.logger.debug('Start loading verticals data')
    global vertical_data
    for filename in glob.glob('verticals/*.csv'):
        for row in csv.reader(open(filename)):
            for i, v in enumerate(row):
                if v:
                    vertical_data['{}-field{}'.format(filename, i)][hash_key(v)] = common.to_unicode(v)
    common.logger.debug('Completed loading verticals data')
# load vertical data in background thread to avoid having to wait
threading.Thread(target=load_data, args=()).start()


def add_model(model, browser):
    global vertical_data
    for field in model.fields:
        key = '{}-field{}'.format(model.key, field)
        vertical_data[key] = VerticalModel(model, field, key, browser)


class VerticalModel:
    """Wrapper around a column generated by a model
    """
    def __init__(self, model, field, key, browser):
        self.model = model
        self.field = field
        self.key = key
        self.browser = browser
        self.col = [hash_key(record[field]) for record in model.records if field in record]
        print 'added vertical model:', [record.get(field) for record in model.records]

    def __contains__(self, key):
        # whether this key is found in the sample data
        return key in self.col

    def itervalues(self):
        # download all remaining results
        # XXX download in separate window?
        global vertical_data
        try:
            vertical_data.pop(self.key)
        except KeyError:
            return
        for url, headers, data in self.model.run():
            print 'SUB itervalues'
            self.browser.load(url=url, headers=headers, data=data)
            js = parser.parse(self.browser.current_text())
            if js:
                for record in parser.json_to_records(js):
                    if self.field in record:
                        yield record[self.field]


def extend(examples):
    """Attempt abstacting these examples
    If successful return a list of similar entities else None"""
    scores = collections.defaultdict(int)
    for example in examples:
        for label, hash_dict in vertical_data.items():
            # use overlap instead of exact match? XXX
            if hash_key(example) in hash_dict:
                scores[label] += 1

    if scores:
        # a perfect score will match all examples
        num_perfect_labels = scores.values().count(len(examples))
        if num_perfect_labels == 1:
            # found that a unique category matched these examples
            label = [key for key in scores if scores[key] == len(examples)][0]
            common.logger.info('Using vertical: {}'.format(label))
            return vertical_data[label].itervalues()
        elif num_perfect_labels == 0:
            # found no category perfectly matched
            common.logger.debug('Partially matched: {}'.format(label))
        else:
            # found multiple categories perfectly matched, so need more examples
            common.logger.info('Multiple keys match all examples: {}'.format([key for key in scores if scores[key] == len(examples)]))

    else:
        # no matches to examples
        common.logger.info('Examples do not match available vertical data: {}'.format(examples))
